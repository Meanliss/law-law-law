"""
Intent Detection & Query Refinement Module
S·ª≠ d·ª•ng LLM Lite ƒë·ªÉ:
1. Ph√°t hi·ªán c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn ph√°p lu·∫≠t
2. Tinh ch·ªânh c√¢u h·ªèi (query refinement)
"""

import re
import json
from typing import Dict, Tuple
from config import INTENT_CONFIDENCE_REJECT_THRESHOLD

# Global cache
_intent_cache = {}


def detect_domain_with_llm(question: str, gemini_lite_model, domain_manager) -> str:
    """
    Use LLM to detect which legal domain a question belongs to
    
    Args:
        question: Sub-question to classify
        gemini_lite_model: Gemini lite model instance
        domain_manager: DomainManager instance
    
    Returns:
        domain_id (str) or None if cannot detect
    """
    try:
        # Get available domains
        domains_info = []
        for domain_id in domain_manager.list_domains():
            # ‚úÖ Fix: Access domain object correctly (not dict)
            domain_obj = domain_manager.domains.get(domain_id)
            if domain_obj:
                domain_name = domain_obj.domain_name
            else:
                domain_name = domain_id
            domains_info.append(f"- {domain_id}: {domain_name}")
        
        domains_list = "\n".join(domains_info)
        
        prompt = f"""B·∫°n l√† chuy√™n gia ph√¢n lo·∫°i c√¢u h·ªèi ph√°p lu·∫≠t.

C√ÇU H·ªéI: "{question}"

C√ÅC Lƒ®NH V·ª∞C PH√ÅP LU·∫¨T:
{domains_list}

NHI·ªÜM V·ª§: X√°c ƒë·ªãnh c√¢u h·ªèi thu·ªôc lƒ©nh v·ª±c ph√°p lu·∫≠t n√†o.

QUY T·∫ÆC:
1. Ch·ªâ tr·∫£ v·ªÅ M·ªòT domain_id ph√π h·ª£p nh·∫•t
2. N·∫øu kh√¥ng r√µ r√†ng, tr·∫£ v·ªÅ "NONE"
3. Ch·ªâ tr·∫£ v·ªÅ domain_id, KH√îNG gi·∫£i th√≠ch

FORMAT TR·∫¢L·ªúI:
DOMAIN: <domain_id ho·∫∑c NONE>

B·∫ÆT ƒê·∫¶U PH√ÇN LO·∫†I:"""

        response = gemini_lite_model.generate_content(prompt)
        text = response.text.strip()
        
        # Parse domain
        domain_match = re.search(r'DOMAIN:\s*(\w+)', text, re.IGNORECASE)
        if domain_match:
            domain = domain_match.group(1).strip()
            if domain.upper() != 'NONE' and domain in domain_manager.list_domains():
                return domain
        
        return None
        
    except Exception as e:
        print(f'[ERROR] LLM domain detection failed: {e}', flush=True)
        return None


def detect_intent_and_refine(query: str, gemini_lite_model, previous_context: str = None) -> tuple:
    """
    S·ª≠ d·ª•ng LLM Lite ƒë·ªÉ:
    1. Ph√°t hi·ªán intent (c√¢u h·ªèi c√≥ li√™n quan ph√°p lu·∫≠t kh√¥ng)
    2. Refine c√¢u h·ªèi (chu·∫©n h√≥a, l√†m r√µ)
    
    Args:
        query: User query
        gemini_lite_model: Gemini lite model instance
        previous_context: Context t·ª´ 2 c√¢u h·ªèi/tr·∫£ l·ªùi tr∆∞·ªõc (optional)
    
    Returns:
        (intent_result, refined_query)
        intent_result: {'is_legal': bool, 'confidence': float, 'reason': str}
        refined_query: C√¢u h·ªèi ƒë√£ ƒë∆∞·ª£c tinh ch·ªânh
    """
    try:
        # ‚úÖ Th√™m context section n·∫øu c√≥
        context_section = ""
        if previous_context:
            context_section = f"""
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
üìö NG·ªÆ C·∫¢NH H·ªòI THO·∫†I TR∆Ø·ªöC:
{previous_context}
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

"""
        
        prompt = f"""{context_section}Ph√¢n t√≠ch c√¢u h·ªèi: "{query}"

NHI·ªÜM V·ª§ 1: C√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn PH√ÅP LU·∫¨T VI·ªÜT NAM kh√¥ng?
- Ph√°p lu·∫≠t bao g·ªìm: Lu·∫≠t, Ngh·ªã ƒë·ªãnh, Th√¥ng t∆∞, Quy ƒë·ªãnh v·ªÅ h√¥n nh√¢n, lao ƒë·ªông, ƒë·∫•t ƒëai, h√¨nh s·ª±, d√¢n s·ª±, h√†nh ch√≠nh, v.v.
- ‚úÖ N·∫æU C√ì NG·ªÆ C·∫¢NH PH√ÅP LU·∫¨T TR∆Ø·ªöC: C√¢u h·ªèi follow-up (nh∆∞ "c√≤n tr∆∞·ªùng h·ª£p n√†y th√¨ sao?", "c·∫£m ∆°n", "gi·∫£i th√≠ch th√™m") c≈©ng ƒë∆∞·ª£c coi l√† c√¢u h·ªèi ph√°p lu·∫≠t

NHI·ªÜM V·ª§ 2: Tinh ch·ªânh c√¢u h·ªèi (n·∫øu l√† c√¢u h·ªèi ph√°p lu·∫≠t):
- Chu·∫©n h√≥a ng√¥n ng·ªØ (s·ª≠a l·ªói ch√≠nh t·∫£, ng·ªØ ph√°p)
- L√†m r√µ √Ω nghƒ©a (th√™m b·ªëi c·∫£nh n·∫øu c·∫ßn)
- Gi·ªØ nguy√™n √Ω ch√≠nh, ng·∫Øn g·ªçn

FORMAT TR·∫¢ L·ªúI (b·∫Øt bu·ªôc):
LEGAL: YES ho·∫∑c NO
CONFIDENCE: 0.XX (t·ª´ 0.00 ƒë·∫øn 1.00)
REASON: l√Ω do ng·∫Øn g·ªçn (1 c√¢u)
REFINED: c√¢u h·ªèi ƒë√£ tinh ch·ªânh (n·∫øu LEGAL=YES) ho·∫∑c NONE (n·∫øu LEGAL=NO)

V√ç D·ª§ 1 (C√¢u h·ªèi ph√°p lu·∫≠t):
LEGAL: YES
CONFIDENCE: 0.95
REASON: H·ªèi v·ªÅ ƒëi·ªÅu ki·ªán k·∫øt h√¥n theo lu·∫≠t
REFINED: ƒê·ªô tu·ªïi k·∫øt h√¥n theo quy ƒë·ªãnh c·ªßa Lu·∫≠t H√¥n nh√¢n v√† Gia ƒë√¨nh Vi·ªát Nam?

V√ç D·ª§ 2 (Kh√¥ng ph·∫£i ph√°p lu·∫≠t):
LEGAL: NO
CONFIDENCE: 0.90
REASON: C√¢u h·ªèi v·ªÅ n·∫•u ƒÉn, kh√¥ng li√™n quan ph√°p lu·∫≠t
REFINED: NONE

B·∫ÆT ƒê·∫¶U PH√ÇN T√çCH:"""
        
        response = gemini_lite_model.generate_content(prompt)
        text = response.text.strip()
        
        print(f'[INTENT+REFINE] LLM Response:\n{text}')
        
        # Parse response
        is_legal = False
        confidence = 0.5
        reason = 'Unknown'
        refined_query = query  # Fallback: gi·ªØ nguy√™n c√¢u g·ªëc
        
        # Extract LEGAL field
        legal_match = re.search(r'LEGAL:\s*(YES|NO)', text, re.IGNORECASE)
        if legal_match:
            is_legal = legal_match.group(1).upper() == 'YES'
        
        # Extract CONFIDENCE
        conf_match = re.search(r'CONFIDENCE:\s*([\d.]+)', text, re.IGNORECASE)
        if conf_match:
            confidence = min(0.98, float(conf_match.group(1)))
        
        # Extract REASON
        reason_match = re.search(r'REASON:\s*(.+?)(?:\n|$)', text, re.IGNORECASE)
        if reason_match:
            reason = reason_match.group(1).strip()[:100]
        
        # Extract REFINED query
        refined_match = re.search(r'REFINED:\s*(.+?)(?:\n|$)', text, re.IGNORECASE | re.DOTALL)
        if refined_match:
            refined_text = refined_match.group(1).strip()
            # N·∫øu l√† c√¢u h·ªèi ph√°p lu·∫≠t v√† c√≥ refined query (kh√¥ng ph·∫£i NONE)
            if is_legal and refined_text.upper() != 'NONE' and len(refined_text) > 5:
                refined_query = refined_text
                print(f'[REFINED] Original: "{query}" ‚Üí Refined: "{refined_query}"')
        
        intent_result = {
            'is_legal': is_legal,
            'confidence': confidence,
            'reason': reason
        }
        
        print(f'[INTENT] is_legal={is_legal}, confidence={confidence:.2f}, reason={reason}')
        
        return intent_result, refined_query
        
    except Exception as e:
        print(f'[ERROR] LLM intent detection failed: {e}')
        # Fallback: Accept v·ªõi confidence th·∫•p
        return {
            'is_legal': True,
            'confidence': 0.4,
            'reason': 'LLM error, fallback to accept'
        }, query


def enhanced_decompose_query(question: str, gemini_lite_model, gemini_flash_model=None, use_advanced=False, domain_manager=None, previous_context: str = None) -> Dict:
    """
    Intent detection + Smart decomposition (with refinement) + Domain detection
    
    Args:
        question: User question (ORIGINAL - kh√¥ng refine tr∆∞·ªõc)
        gemini_lite_model: Gemini lite model instance (for Fast mode)
        gemini_flash_model: Gemini flash model instance (for Quality mode) - OPTIONAL
        use_advanced: True = Quality mode (d√πng Flash cho decompose), False = Fast mode (d√πng Lite)
        domain_manager: DomainManager instance for domain detection - OPTIONAL
        previous_context: Context t·ª´ 2 c√¢u h·ªèi/tr·∫£ l·ªùi tr∆∞·ªõc (optional)
    
    Returns:
        {
            'sub_questions': List[{'question': str, 'domain': str}],  # Includes ORIGINAL + decomposed (refined inside)
            'intent': dict,
            'should_process': bool,
            'method': str
        }
    """
    from .query_expansion import decompose_query_smart
    
    # ‚úÖ Step 1: Intent detection ONLY (kh√¥ng refine ri√™ng n·ªØa)
    print(f'\n[INTENT] Checking if legal: "{question}"', flush=True)
    
    # Detect intent without refining (refine will be inside decompose)
    prompt = f"""C√¢u h·ªèi: "{question}"

ƒê√¢y c√≥ ph·∫£i c√¢u h·ªèi ph√°p lu·∫≠t Vi·ªát Nam kh√¥ng?
- YES n·∫øu h·ªèi v·ªÅ lu·∫≠t, quy ƒë·ªãnh, quy·ªÅn l·ª£i, nghƒ©a v·ª•, th·ªß t·ª•c ph√°p l√Ω
- NO n·∫øu: ch√†o h·ªèi, to√°n h·ªçc, l·∫≠p tr√¨nh, n·∫•u ƒÉn, du l·ªãch, gi·∫£i tr√≠, th·ªÉ thao, v.v.

Tr·∫£ l·ªùi JSON:
{{"is_legal": true/false, "confidence": 0.0-1.0, "reason": "..."}}"""
    
    try:
        response = gemini_lite_model.generate_content(prompt)
        result_text = response.text.strip()
        
        # Parse JSON
        json_match = re.search(r'\{[^}]+\}', result_text)
        if json_match:
            intent = json.loads(json_match.group(0))
        else:
            intent = {'is_legal': True, 'confidence': 0.5, 'reason': 'Cannot parse, assume legal'}
    except Exception as e:
        print(f'[INTENT] Error: {e}', flush=True)
        intent = {'is_legal': True, 'confidence': 0.4, 'reason': 'LLM error, fallback to accept'}
    
    # ‚úÖ Step 2: Reject if not legal
    if not intent['is_legal'] and intent['confidence'] >= INTENT_CONFIDENCE_REJECT_THRESHOLD:
        print(f'[INTENT] REJECTED: {intent["reason"]}', flush=True)
        return {
            'sub_questions': [],
            'intent': intent,
            'should_process': False,
            'method': 'rejected'
        }
    
    # ‚úÖ Step 3: Smart decomposition (bao g·ªìm c·∫£ refine + decompose)
    # Quality mode: D√πng Flash (reasoning t·ªët h∆°n, t√°ch c√¢u ph·ª©c t·∫°p ch√≠nh x√°c h∆°n)
    # Fast mode: D√πng Lite (nhanh h∆°n)
    decompose_model = gemini_flash_model if (use_advanced and gemini_flash_model) else gemini_lite_model
    model_name = "Flash (Quality)" if (use_advanced and gemini_flash_model) else "Lite (Fast)"
    
    print(f'[DECOMPOSE+REFINE] Using {model_name} for: "{question}"', flush=True)
    decompose_result = decompose_query_smart(question, decompose_model)  # ‚úÖ Truy·ªÅn original question
    
    # ‚úÖ Step 4: Build sub_questions with original + decomposed (refined)
    sub_questions = []
    
    # Detect domain for original question
    original_domain = None
    if domain_manager:
        original_domain = detect_domain_with_llm(question, gemini_lite_model, domain_manager)
        if not original_domain:
            original_domain = domain_manager.detect_domain_from_keywords(question)
        if original_domain:
            print(f'üéØ [DOMAIN] Original query ‚Üí {original_domain}', flush=True)
    
    # Add ORIGINAL question as FIRST sub-question (kh√¥ng refine)
    sub_questions.append({
        'question': question,  # ‚úÖ Gi·ªØ nguy√™n c√¢u h·ªèi g·ªëc
        'domain': original_domain,
        'is_original': True  # Mark as original
    })
    
    # Then add decomposed (refined) sub-questions
    for sub_query in decompose_result['sub_queries']:
        # Skip if sub_query gi·ªëng h·ªát original (avoid duplication)
        if sub_query.strip().lower() == question.strip().lower():
            continue
            
        sub_q_obj = {
            'question': sub_query,  # ‚úÖ ƒê√¢y l√† c√¢u ƒë√£ refined + decomposed
            'domain': None,
            'is_original': False
        }
        
        # Detect domain for sub-question
        if domain_manager:
            # Use LLM to detect domain (more accurate than keywords)
            detected_domain = detect_domain_with_llm(sub_query, gemini_lite_model, domain_manager)
            if detected_domain:
                sub_q_obj['domain'] = detected_domain
                print(f'üéØ [DOMAIN-LLM] "{sub_query}" ‚Üí {detected_domain}', flush=True)
            else:
                # Fallback to keyword matching
                detected_domain = domain_manager.detect_domain_from_keywords(sub_query)
                if detected_domain:
                    sub_q_obj['domain'] = detected_domain
                    print(f'üîë [DOMAIN-KEYWORD] "{sub_query}" ‚Üí {detected_domain}', flush=True)
        
        sub_questions.append(sub_q_obj)
    
    return {
        'sub_questions': sub_questions,  # ‚úÖ Original + refined/decomposed
        'intent': intent,
        'should_process': decompose_result['should_process'],
        'method': decompose_result['method']
    }


def get_cache_size() -> int:
    """Get current intent cache size"""
    return len(_intent_cache)


def clear_cache():
    """Clear intent cache"""
    global _intent_cache
    _intent_cache = {}
